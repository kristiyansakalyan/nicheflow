{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810e8384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import scanpy as sc  # type: ignore\n",
    "from moscot import datasets as mds\n",
    "from nicheflow.preprocessing.h5ad_dataset_type import load_h5ad_dataset_dataclass\n",
    "from nicheflow.preprocessing.h5ad_preprocessor import H5ADPreprocessor\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a6efe1",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a37e177",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(preprocessor: H5ADPreprocessor) -> None:\n",
    "    timepoints = list(preprocessor.subsampled_timepoint_idx.keys())\n",
    "    num_timepoints = len(timepoints)\n",
    "    cols = 5\n",
    "    rows = math.ceil(num_timepoints / cols)\n",
    "\n",
    "    if rows == 1:\n",
    "        cols = min(5, num_timepoints)\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 4, rows * 4), squeeze=False)\n",
    "    fig.subplots_adjust(wspace=0.3, hspace=0.4)\n",
    "\n",
    "    i = 0\n",
    "    for timepoint in timepoints:\n",
    "        row = i // cols\n",
    "        col = i % cols\n",
    "        ax = axes[row][col]\n",
    "\n",
    "        coords = preprocessor.coords[preprocessor.timepoint_indices[timepoint]]\n",
    "        centroid_indices = preprocessor.subsampled_timepoint_idx[timepoint]\n",
    "\n",
    "        # Plot background cells\n",
    "        ax.scatter(coords[:, 0], coords[:, 1], s=5, color=(0.95, 0.95, 0.95))\n",
    "        # Plot centroids\n",
    "        ax.scatter(\n",
    "            coords[centroid_indices][:, 0], coords[centroid_indices][:, 1], s=5, label=\"Centroids\"\n",
    "        )\n",
    "\n",
    "        ax.set_title(str(timepoint))\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_frame_on(False)\n",
    "        ax.legend(loc=\"upper right\", fontsize=8)\n",
    "        i += 1\n",
    "\n",
    "    # Hide unused axes\n",
    "    for j in range(i, rows * cols):\n",
    "        row = j // cols\n",
    "        col = j % cols\n",
    "        axes[row][col].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e591ad",
   "metadata": {},
   "source": [
    "# Downloading the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cdff73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first make the data folder\n",
    "data_folder = Path(\"../data\")\n",
    "data_folder.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf46885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_save(url: str, output_file: Path) -> None:\n",
    "    response = requests.get(url, stream=True)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    total_size = int(response.headers.get(\"content-length\", 0))\n",
    "    chunk_size = 1024  # 1 KB\n",
    "\n",
    "    with (\n",
    "        open(output_file, \"wb\") as file,\n",
    "        tqdm(\n",
    "            desc=\"Downloading\",\n",
    "            total=total_size,\n",
    "            unit=\"B\",\n",
    "            unit_scale=True,\n",
    "            unit_divisor=1024,\n",
    "        ) as bar,\n",
    "    ):\n",
    "        for chunk in response.iter_content(chunk_size=chunk_size):\n",
    "            file.write(chunk)\n",
    "            bar.update(len(chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bed259",
   "metadata": {},
   "outputs": [],
   "source": [
    "aging_url = \"https://zenodo.org/records/13883177/files/aging_coronal.h5ad?download=1\"\n",
    "aging_output_file = data_folder.joinpath(\"aging_coronal.h5ad\")\n",
    "\n",
    "axolotl_dev_url = \"https://figshare.com/ndownloader/files/44714629\"\n",
    "axolotl_dev_output_file = data_folder.joinpath(\"axolotl_development.h5ad\")\n",
    "\n",
    "download_and_save(url=aging_url, output_file=aging_output_file)\n",
    "download_and_save(url=axolotl_dev_url, output_file=axolotl_dev_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977597eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_moscot = mds.mosta()\n",
    "adata_moscot.obs[\"time\"] = adata_moscot.obs[\"time\"].astype(\"category\")\n",
    "adata_moscot.layers[\"counts\"] = adata_moscot.X.copy()\n",
    "\n",
    "# Write it down\n",
    "moscot_output_file = data_folder.joinpath(\"moscot.h5ad\")\n",
    "adata_moscot.write_h5ad(moscot_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9953215f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate that the datasets have been downloaded\n",
    "assert aging_output_file.exists()\n",
    "assert axolotl_dev_output_file.exists()\n",
    "assert moscot_output_file.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca21383",
   "metadata": {},
   "source": [
    "# Manually perprocess the AnnData with scanpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e010bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "moscot_output_file = Path(\"/nfs/homedirs/sakalyan/code/cellular-graph-flow/data/moscot.h5ad\")\n",
    "axolotl_dev_output_file = Path(\"/nfs/homedirs/sakalyan/code/cellular-graph-flow/data/axolotl_development.h5ad\")\n",
    "aging_output_file = Path(\"/nfs/homedirs/sakalyan/code/cellular-graph-flow/data/aging_coronal.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eeb9124",
   "metadata": {},
   "outputs": [],
   "source": [
    "moscot_adata = sc.read_h5ad(moscot_output_file)\n",
    "print(\"Loaded the embryonic development dataset\")\n",
    "\n",
    "axolotl_adata = sc.read_h5ad(axolotl_dev_output_file)\n",
    "print(\"Loaded the axolotl brain development dataset\")\n",
    "\n",
    "aging_adata = sc.read_h5ad(aging_output_file)\n",
    "print(\"Loaded the mouse brain aging dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bc299e",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_PRINCIPAL_COMPONENTS = 50\n",
    "N_TOP_GENES = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124966ed",
   "metadata": {},
   "source": [
    "### Embryonic development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f4b9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.pca(moscot_adata, n_comps=N_PRINCIPAL_COMPONENTS)\n",
    "\n",
    "# Set dataset-specific attributes\n",
    "moscot_timepoint_column = \"timepoint\"\n",
    "moscot_cell_type_column = \"annotation\"\n",
    "\n",
    "# Timepoints\n",
    "moscot_timepoints_ordered = sorted(\n",
    "    set(moscot_adata.obs[moscot_timepoint_column].cat.categories),\n",
    "    key=lambda x: float(x[1:]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54987279",
   "metadata": {},
   "outputs": [],
   "source": [
    "moscot_timepoints_ordered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae78fa1",
   "metadata": {},
   "source": [
    "### Axolotl brain development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f359c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.highly_variable_genes(axolotl_adata, n_top_genes=N_TOP_GENES, subset=True)\n",
    "print(\"Finished selecting the highly variable genes\")\n",
    "\n",
    "sc.pp.pca(axolotl_adata, n_comps=N_PRINCIPAL_COMPONENTS)\n",
    "print(\"PCA is done\")\n",
    "\n",
    "# Set dataset-specific attributes\n",
    "axolotl_timepoint_column = \"condition\"\n",
    "axolotl_cell_type_column = \"Annotation\"\n",
    "\n",
    "# Timepoints\n",
    "axolotl_timepoints_ordered = [\n",
    "    \"Stage44\",\n",
    "    \"Stage54\",\n",
    "    \"Stage57\",\n",
    "    \"Injury control\",\n",
    "    \"Adult\",\n",
    "    \"Meta\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2d8f85",
   "metadata": {},
   "source": [
    "### Mouse brain aging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f8e6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "aging_adata.layers[\"counts\"] = aging_adata.X.copy()\n",
    "sc.pp.normalize_total(aging_adata)\n",
    "print(\"Finished the total normalization\")\n",
    "\n",
    "sc.pp.log1p(aging_adata)\n",
    "print(\"Finished log1p\")\n",
    "\n",
    "sc.pp.pca(aging_adata, n_comps=N_PRINCIPAL_COMPONENTS)\n",
    "print(\"PCA is done\")\n",
    "\n",
    "fraction = 0.2\n",
    "sc.pp.subsample(aging_adata, fraction)\n",
    "print(\"Subsampling is done\")\n",
    "\n",
    "# Set dataset-specific attributes\n",
    "aging_timepoint_column = \"age\"\n",
    "aging_cell_type_column = \"celltype\"\n",
    "\n",
    "# Timepoints\n",
    "aging_timepoints_ordered = sorted(set(aging_adata.obs[aging_timepoint_column]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d4a77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aging_timepoints_ordered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ee6efe",
   "metadata": {},
   "source": [
    "# Use the H5AD Preprocessor\n",
    "\n",
    "It will \n",
    "- normalize the positions of the cells\n",
    "- standardize the PCA components\n",
    "- compute the microenvironments with the given radius\n",
    "- create a discrete set of test microenvironments that ensure almost full slide coverage\n",
    "- store the data to avoid recomputation during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1513a0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "moscot_save_filepath = data_folder.joinpath(\"embryonic_data.pkl\")\n",
    "axolotl_save_filepath = data_folder.joinpath(\"axolotl_brain_dev.pkl\")\n",
    "aging_save_filepath = data_folder.joinpath(\"mouse_brain_aging.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414b70a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_process: list[tuple[sc.AnnData, str, str, list[Any], str]] = [\n",
    "    (\n",
    "        moscot_adata,\n",
    "        moscot_timepoint_column,\n",
    "        moscot_cell_type_column,\n",
    "        moscot_timepoints_ordered,\n",
    "        str(moscot_save_filepath),\n",
    "    ),\n",
    "    (\n",
    "        axolotl_adata,\n",
    "        axolotl_timepoint_column,\n",
    "        axolotl_cell_type_column,\n",
    "        axolotl_timepoints_ordered,\n",
    "        str(axolotl_save_filepath),\n",
    "    ),\n",
    "    (\n",
    "        aging_adata,\n",
    "        aging_timepoint_column,\n",
    "        aging_cell_type_column,\n",
    "        aging_timepoints_ordered,\n",
    "        str(aging_save_filepath),\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7063a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "for adata, timepoint_column, cell_type_column, timepoints_ordered, save_filepath in data_to_process:\n",
    "    preprocessor = H5ADPreprocessor(\n",
    "        timepoint_column=timepoint_column,\n",
    "        cell_type_column=cell_type_column,\n",
    "        timepoints_ordered=timepoints_ordered,\n",
    "        standardize_coordinates=True,\n",
    "        radius=0.15,\n",
    "        dx=0.15,\n",
    "        dy=0.2,\n",
    "        device=\"cpu\",\n",
    "        chunk_size=1000,\n",
    "        # This will fix the number of microenvironments\n",
    "        # in the test dataset for each timepoint to be the same.\n",
    "        fixed_microenvironments=True,\n",
    "    )\n",
    "\n",
    "    # Preprocess the data\n",
    "    preprocessor.preprocess_data(adata)\n",
    "\n",
    "    # Save the data\n",
    "    preprocessor.save(save_filepath)\n",
    "\n",
    "    # Let's plot the data with the centroids chosen for testing\n",
    "    plot_data(preprocessor=preprocessor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd2ff1c",
   "metadata": {},
   "source": [
    "# Data loading\n",
    "\n",
    "Now you can also load the dataset dataclass that holds both the data and information about the preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95218ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dataclass = load_h5ad_dataset_dataclass(str(moscot_save_filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21da65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dataclass.timepoint_num_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76c0945",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dataclass.X_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df42bb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.zeros((10, 10)).device.type"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nicheflow-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
